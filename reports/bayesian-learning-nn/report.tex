\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[left=2cm, right=2cm, top=2.5cm, bottom=2.0cm]{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage[font={small,it}]{caption}
\graphicspath{ {figures/} }
\usepackage{url}
\usepackage{appendix}
\usepackage{float}
\usepackage[bottom]{footmisc}
\usepackage{titling}
\setlength{\droptitle}{-10em}  

\title{ \huge Artificial neural networks \\ 
  { \large Assignment 2: Bayesian learning in neural networks }}
\author{
        Lood, CÃ©dric \\
        \small Master of Bioinformatics
}

\begin{document}
\maketitle
%\tableofcontents

\section{Context}
Bayesian statistics offer a robust framework in which it is possible
to build and assess models, and perform inference.

In this exercise, we were asked to explore bayesian learning applied
to neural networks. Using the Bayes rule in the context of learning
has several desirable properties related to the fact that one is not
using point estimates in the search space of solutions (for example
the weight space) but tries to obtain a distribution over the weight
space. Hence, quantification of certainty of predictions is possible
without the use of validation set or resampling.

\section{Decision boundary of classifier}

In this section, I investigated whether a simple bayesian approach
could classify correctly data generated by a perceptron (hence
linearly separable). In terms of architecture, the perceptron created
consisted of 1 neuron with 2 inputs taking values in $[-1; 1]$,
without bias term. The output of the perceptron is in $\{-1, 1\}$

Figure \ref{fig:perceptron_bayes} displays the classifiers on top of
the dataset (top left-hand side figure). You can see that the
classifier generated using the Bayes rule is pretty close to the
perceptron used to generate the dataset. There seemed to be exceptions
to that, and in a few cases the classifier was off. 

For some reason, the convergence of the posterior through the
iterative updates always entailed that one of the weight (w1 or w2)
was set to 1, while the other varied. I did not see exception to that
when running the script multiple times.

The bottom, right-hand side graphic depicts the so-called contour
lines of the posterior distribution over the weight space. As
mentioned before, the posterior always comprised one of the weight set
to 1, and thus the contour plot is always glued to one of the external
border/constrains of the weight space. The red asterisk represents the
weights of the perceptron. This could take any value in $[-1; 1]$, so
it happened during some runs that the 2 did not concord much. However,
often the weights of the perceptron were in the vicinity of that of
the most probable posterior ones.

\begin{figure}[H]
    \centering
    \includegraphics[scale=.40]{perceptron_bayes.pdf}
    \caption{Comparison of perceptron and bayes classifier for dataset
      generated by perceptron}
    \label{fig:perceptron_bayes}
\end{figure}


\section{Function approximation}

\bibliographystyle{ieeetr} 
\bibliography{bib-db}

\end{document}
